{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYbeqK0tYenp"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og59Z62aZJna"
      },
      "source": [
        "Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVY05GIhZEMM"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbEcqWhqgDmH"
      },
      "outputs": [],
      "source": [
        "tensorboard_log = \"data/tb/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-1scts3Y1c7"
      },
      "outputs": [],
      "source": [
        "dqn_model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    verbose=1,\n",
        "    train_freq=16,\n",
        "    gradient_steps=8,\n",
        "    gamma=0.99,\n",
        "    exploration_fraction=0.2,\n",
        "    exploration_final_eps=0.07,\n",
        "    target_update_interval=600,\n",
        "    learning_starts=1000,\n",
        "    buffer_size=10000,\n",
        "    batch_size=128,\n",
        "    learning_rate=4e-3,\n",
        "    policy_kwargs=dict(net_arch=[256, 256]),\n",
        "    tensorboard_log=tensorboard_log,\n",
        "    seed=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNoFwsCPZQuz"
      },
      "source": [
        "Evaluate the agent before training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn0C7RHyZTHA"
      },
      "outputs": [],
      "source": [
        "mean_reward, std_reward = evaluate_policy(\n",
        "    dqn_model,\n",
        "    dqn_model.get_env(),\n",
        "    deterministic=True,\n",
        "    n_eval_episodes=20,\n",
        ")\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM0m1NyAgVhR"
      },
      "outputs": [],
      "source": [
        "# Optional: Monitor training in tensorboard\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir $tensorboard_log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUoPUfQ4ZexC"
      },
      "source": [
        "We will first train the agent until convergence and then analyse the learned q-value function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wKP0gKjZgWZ"
      },
      "outputs": [],
      "source": [
        "dqn_model.learn(int(1.2e5), log_interval=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI8xh463Zi7M"
      },
      "source": [
        "Evaluate after training, the mean episodic reward should have improved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z952YogYZ8yD"
      },
      "outputs": [],
      "source": [
        "mean_reward, std_reward = evaluate_policy(dqn_model, dqn_model.get_env(), deterministic=True, n_eval_episodes=20)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Prepare video recording"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLzXxO8VMD6N"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTRNUfulOGaF"
      },
      "source": [
        "We will record a video using the [VecVideoRecorder](https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html#vecvideorecorder) wrapper, you will learn about those wrapper in the next notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trag9dQpOIhx"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "\n",
        "def record_video(\n",
        "    env_id,\n",
        "    model,\n",
        "    video_length=500,\n",
        "    prefix=\"\",\n",
        "    video_folder=\"videos/\",\n",
        "):\n",
        "    \"\"\"\n",
        "    :param env_id: (str)\n",
        "    :param model: (RL model)\n",
        "    :param video_length: (int)\n",
        "    :param prefix: (str)\n",
        "    :param video_folder: (str)\n",
        "    \"\"\"\n",
        "    eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "    # Start the video at step=0 and record 500 steps\n",
        "    eval_env = VecVideoRecorder(\n",
        "        eval_env,\n",
        "        video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0,\n",
        "        video_length=video_length,\n",
        "        name_prefix=prefix,\n",
        "    )\n",
        "\n",
        "    obs = eval_env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs, deterministic=False)\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "    # Close the video recorder\n",
        "    eval_env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvVGX13xaGbf"
      },
      "outputs": [],
      "source": [
        "record_video(\"LunarLander-v2\", dqn_model, video_length=500, prefix=\"dqn-lunar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHaYvk8uaK70"
      },
      "outputs": [],
      "source": [
        "show_videos(\"videos\", prefix=\"dqn\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xVm9QPNVwKXN"
      ],
      "name": "dqn_sb3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
